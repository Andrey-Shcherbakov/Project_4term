{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Алгоритмы без ML\n",
    "\n",
    "Здесь используются разные методы преобразования звукового сигнала, некоторые из которых даже работают (по моим личным ощущениям). Основных минуса 2:\n",
    "1. Надо перебирать все методы вручную и самостоятельно определять, какой из результатов 'лучший', откуда вытекает\n",
    "2. Даже если пытаться сделать модель машинного обучения, возникает проблема с тем, как параметризовать для компьютера субъективное восприятие звука человеческим ухом. Сложно автоматически определить, где качество звука 'лучше'.\n",
    "\n",
    "*Замечание*. В программе используется питоновская библиотека `pysndfx`, которая работает как интерфейс между UNIX-утилитой `sox` и самим питоном. Чтобы все заработало, ее нужно заранее установить (этот пункт нужно включить в установщик, если он у на будет)\n",
    "\n",
    "**В презентации нужно:** Описать все эти методы с точки зрения физики, например 'вот тут мы в спектре обрезаем все выше 10 кГц, а вот здесь усиливаем средние частоты' и т.д. Для этого хорошо бы в этом самим разобраться"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pysndfx in /Users/macbookpro/anaconda3/lib/python3.7/site-packages (0.3.6)\n",
      "Requirement already satisfied: numpy in /Users/macbookpro/anaconda3/lib/python3.7/site-packages (from pysndfx) (1.15.4)\n",
      "Requirement already satisfied: python_speech_features in /Users/macbookpro/anaconda3/lib/python3.7/site-packages (0.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install pysndfx\n",
    "!pip install python_speech_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "from pysndfx import AudioEffectsChain\n",
    "import numpy as np\n",
    "import math\n",
    "import python_speech_features\n",
    "import scipy as sp\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В коде ниже фигурирует название папки `assets/`. Тут по-хорошему нужно написать что-то вроде `try: mkdir('assets/')`, но для работы это не принципиально. Но в финалке лучше это сделать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''------------------------------------\n",
    "FILE READER:\n",
    "    receives filename,\n",
    "    returns audio time series (y) and sampling rate of y (sr)\n",
    "------------------------------------'''\n",
    "def read_file(file_name):\n",
    "    sample_file = file_name\n",
    "    sample_directory = 'assets/'\n",
    "    sample_path = sample_directory + sample_file\n",
    "\n",
    "    # generating audio time series and a sampling rate (int)\n",
    "    y, sr = librosa.load(sample_path)\n",
    "\n",
    "    return y, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''------------------------------------\n",
    "NOISE REDUCTION USING POWER:\n",
    "    receives an audio matrix,\n",
    "    returns the matrix after gain reduction on noise\n",
    "------------------------------------'''\n",
    "def reduce_noise_power(y, sr):\n",
    "\n",
    "    cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "\n",
    "    threshold_h = round(np.median(cent))*1.5\n",
    "    threshold_l = round(np.median(cent))*0.1\n",
    "\n",
    "    less_noise = AudioEffectsChain().lowshelf(gain=-30.0, frequency=threshold_l, slope=0.8).highshelf(gain=-12.0, frequency=threshold_h, slope=0.5).limiter(gain=6.0)\n",
    "    y_clean = less_noise(y)\n",
    "\n",
    "    return y_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''------------------------------------\n",
    "NOISE REDUCTION USING CENTROID ANALYSIS:\n",
    "    receives an audio matrix,\n",
    "    returns the matrix after gain reduction on noise\n",
    "------------------------------------'''\n",
    "\n",
    "def reduce_noise_centroid_s(y, sr):\n",
    "\n",
    "    cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "\n",
    "    threshold_h = np.max(cent)\n",
    "    threshold_l = np.min(cent)\n",
    "\n",
    "    less_noise = AudioEffectsChain().lowshelf(gain=-12.0, frequency=threshold_l, slope=0.5).highshelf(gain=-12.0, frequency=threshold_h, slope=0.5).limiter(gain=6.0)\n",
    "\n",
    "    y_cleaned = less_noise(y)\n",
    "\n",
    "    return y_cleaned\n",
    "\n",
    "\n",
    "def reduce_noise_centroid_mb(y, sr):\n",
    "\n",
    "    cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "\n",
    "    threshold_h = np.max(cent)\n",
    "    threshold_l = np.min(cent)\n",
    "\n",
    "    less_noise = AudioEffectsChain().lowshelf(gain=-30.0, frequency=threshold_l, slope=0.5).highshelf(gain=-30.0, frequency=threshold_h, slope=0.5).limiter(gain=10.0)\n",
    "    # less_noise = AudioEffectsChain().lowpass(frequency=threshold_h).highpass(frequency=threshold_l)\n",
    "    y_cleaned = less_noise(y)\n",
    "\n",
    "\n",
    "    cent_cleaned = librosa.feature.spectral_centroid(y=y_cleaned, sr=sr)\n",
    "    columns, rows = cent_cleaned.shape\n",
    "    boost_h = math.floor(rows/3*2)\n",
    "    boost_l = math.floor(rows/6)\n",
    "    boost = math.floor(rows/3)\n",
    "\n",
    "    # boost_bass = AudioEffectsChain().lowshelf(gain=20.0, frequency=boost, slope=0.8)\n",
    "    boost_bass = AudioEffectsChain().lowshelf(gain=16.0, frequency=boost_h, slope=0.5)#.lowshelf(gain=-20.0, frequency=boost_l, slope=0.8)\n",
    "    y_clean_boosted = boost_bass(y_cleaned)\n",
    "\n",
    "    return y_clean_boosted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''------------------------------------\n",
    "NOISE REDUCTION USING MFCC:\n",
    "    receives an audio matrix,\n",
    "    returns the matrix after gain reduction on noise\n",
    "------------------------------------'''\n",
    "def reduce_noise_mfcc_down(y, sr):\n",
    "\n",
    "    hop_length = 512\n",
    "\n",
    "    ## librosa\n",
    "    # mfcc = librosa.feature.mfcc(y=y, sr=sr, hop_length=hop_length, n_mfcc=13)\n",
    "    # librosa.mel_to_hz(mfcc)\n",
    "\n",
    "    ## mfcc\n",
    "    mfcc = python_speech_features.base.mfcc(y)\n",
    "    mfcc = python_speech_features.base.logfbank(y)\n",
    "    mfcc = python_speech_features.base.lifter(mfcc)\n",
    "\n",
    "    sum_of_squares = []\n",
    "    index = -1\n",
    "    for r in mfcc:\n",
    "        sum_of_squares.append(0)\n",
    "        index = index + 1\n",
    "        for n in r:\n",
    "            sum_of_squares[index] = sum_of_squares[index] + n**2\n",
    "\n",
    "    strongest_frame = sum_of_squares.index(max(sum_of_squares))\n",
    "    hz = python_speech_features.base.mel2hz(mfcc[strongest_frame])\n",
    "\n",
    "    max_hz = max(hz)\n",
    "    min_hz = min(hz)\n",
    "\n",
    "    speech_booster = AudioEffectsChain().highshelf(frequency=min_hz*(-1)*1.2, gain=-12.0, slope=0.6).limiter(gain=8.0)\n",
    "    y_speach_boosted = speech_booster(y)\n",
    "\n",
    "    return (y_speach_boosted)\n",
    "\n",
    "\n",
    "def reduce_noise_mfcc_up(y, sr):\n",
    "\n",
    "    hop_length = 512\n",
    "\n",
    "    ## librosa\n",
    "    # mfcc = librosa.feature.mfcc(y=y, sr=sr, hop_length=hop_length, n_mfcc=13)\n",
    "    # librosa.mel_to_hz(mfcc)\n",
    "\n",
    "    ## mfcc\n",
    "    mfcc = python_speech_features.base.mfcc(y)\n",
    "    mfcc = python_speech_features.base.logfbank(y)\n",
    "    mfcc = python_speech_features.base.lifter(mfcc)\n",
    "\n",
    "    sum_of_squares = []\n",
    "    index = -1\n",
    "    for r in mfcc:\n",
    "        sum_of_squares.append(0)\n",
    "        index = index + 1\n",
    "        for n in r:\n",
    "            sum_of_squares[index] = sum_of_squares[index] + n**2\n",
    "\n",
    "    strongest_frame = sum_of_squares.index(max(sum_of_squares))\n",
    "    hz = python_speech_features.base.mel2hz(mfcc[strongest_frame])\n",
    "\n",
    "    max_hz = max(hz)\n",
    "    min_hz = min(hz)\n",
    "\n",
    "    speech_booster = AudioEffectsChain().lowshelf(frequency=min_hz*(-1), gain=12.0, slope=0.5)#.highshelf(frequency=min_hz*(-1)*1.2, gain=-12.0, slope=0.5)#.limiter(gain=8.0)\n",
    "    y_speach_boosted = speech_booster(y)\n",
    "\n",
    "    return (y_speach_boosted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''------------------------------------\n",
    "NOISE REDUCTION USING MEDIAN:\n",
    "    receives an audio matrix,\n",
    "    returns the matrix after gain reduction on noise\n",
    "------------------------------------'''\n",
    "\n",
    "def reduce_noise_median(y, sr):\n",
    "    y = sp.signal.medfilt(y,3)\n",
    "    return (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''------------------------------------\n",
    "SILENCE TRIMMER:\n",
    "    receives an audio matrix,\n",
    "    returns an audio matrix with less silence and the amout of time that was trimmed\n",
    "------------------------------------'''\n",
    "def trim_silence(y):\n",
    "    y_trimmed, index = librosa.effects.trim(y, top_db=20, frame_length=2, hop_length=500)\n",
    "    trimmed_length = librosa.get_duration(y) - librosa.get_duration(y_trimmed)\n",
    "\n",
    "    return y_trimmed, trimmed_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''------------------------------------\n",
    "AUDIO ENHANCER:\n",
    "    receives an audio matrix,\n",
    "    returns the same matrix after audio manipulation\n",
    "------------------------------------'''\n",
    "def enhance(y):\n",
    "    apply_audio_effects = AudioEffectsChain().lowshelf(gain=10.0, frequency=260, slope=0.1).reverb(reverberance=25, hf_damping=5, room_scale=5, stereo_depth=50, pre_delay=20, wet_gain=0, wet_only=False)#.normalize()\n",
    "    y_enhanced = apply_audio_effects(y)\n",
    "\n",
    "    return y_enhanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''------------------------------------\n",
    "OUTPUT GENERATOR:\n",
    "    receives a destination path, file name, audio matrix, and sample rate,\n",
    "    generates a wav file based on input\n",
    "------------------------------------'''\n",
    "def output_file(destination ,filename, y, sr, ext=\"\"):\n",
    "    destination = destination + filename[:-4] + ext + '.wav'\n",
    "    librosa.output.write_wav(destination, y, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''------------------------------------\n",
    "LOGIC:\n",
    "    [1] load file\n",
    "    [2] reduce noise\n",
    "    [3] trim silence\n",
    "    [4] output file\n",
    "sample files:\n",
    "    01_counting.m4a\n",
    "    02_wind_and_cars.m4a\n",
    "    03_truck.m4a\n",
    "    04_voices.m4a\n",
    "    05_ambeint.m4a\n",
    "    06_office.m4a\n",
    "------------------------------------'''\n",
    "\n",
    "from os import mkdir\n",
    "\n",
    "samples = ['01_counting.m4a','02_wind_and_cars.m4a','03_truck.m4a','04_voices.m4a','05_ambeint.m4a','06_office.m4a']\n",
    "\n",
    "for s in samples:\n",
    "    # reading a file\n",
    "    filename = s\n",
    "    y, sr = read_file(filename)\n",
    "\n",
    "    # reducing noise using db power\n",
    "    y_reduced_power = reduce_noise_power(y, sr)\n",
    "    y_reduced_centroid_s = reduce_noise_centroid_s(y, sr)\n",
    "    y_reduced_centroid_mb = reduce_noise_centroid_mb(y, sr)\n",
    "    y_reduced_mfcc_up = reduce_noise_mfcc_up(y, sr)\n",
    "    y_reduced_mfcc_down = reduce_noise_mfcc_down(y, sr)\n",
    "    y_reduced_median = reduce_noise_median(y, sr)\n",
    "\n",
    "    # trimming silences\n",
    "    y_reduced_power, time_trimmed = trim_silence(y_reduced_power)\n",
    "    # print (time_trimmed)\n",
    "\n",
    "    y_reduced_centroid_s, time_trimmed = trim_silence(y_reduced_centroid_s)\n",
    "    # print (time_trimmed)\n",
    "\n",
    "    y_reduced_power, time_trimmed = trim_silence(y_reduced_power)\n",
    "    # print (time_trimmed)\n",
    "\n",
    "    y_reduced_centroid_mb, time_trimmed = trim_silence(y_reduced_centroid_mb)\n",
    "    # print (time_trimmed)\n",
    "\n",
    "    y_reduced_mfcc_up, time_trimmed = trim_silence(y_reduced_mfcc_up)\n",
    "    # print (time_trimmed)\n",
    "\n",
    "    y_reduced_mfcc_down, time_trimmed = trim_silence(y_reduced_mfcc_down)\n",
    "    # print (time_trimmed)\n",
    "\n",
    "    y_reduced_median, time_trimmed = trim_silence(y_reduced_median)\n",
    "\n",
    "    # generating output file [1]\n",
    "    try:\n",
    "        mkdir('01_samples_trimmed_noise_reduced/')\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    \n",
    "    output_file('01_samples_trimmed_noise_reduced/' ,filename, y_reduced_power, sr, '_pwr')\n",
    "    output_file('01_samples_trimmed_noise_reduced/' ,filename, y_reduced_centroid_s, sr, '_ctr_s')\n",
    "    output_file('01_samples_trimmed_noise_reduced/' ,filename, y_reduced_centroid_mb, sr, '_ctr_mb')\n",
    "    output_file('01_samples_trimmed_noise_reduced/' ,filename, y_reduced_mfcc_up, sr, '_mfcc_up')\n",
    "    output_file('01_samples_trimmed_noise_reduced/' ,filename, y_reduced_mfcc_down, sr, '_mfcc_down')\n",
    "    output_file('01_samples_trimmed_noise_reduced/' ,filename, y_reduced_median, sr, '_median')\n",
    "    output_file('01_samples_trimmed_noise_reduced/' ,filename, y, sr, '_org')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
